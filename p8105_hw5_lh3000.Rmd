---
title: "Homework 5"
author: "Lunbei Hu"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---

This is my solution to HW5.

```{r setup, include = FALSE}
library(tidyverse)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.color = "viridis",
  ggplot2.continuous.fill = "viridis"
)  

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

The raw dataset contains information about criminal homicides in 50 large U.S. cities from 2012 to 2017, collected by The Washington Post. The variable included are the location of the killing, the report date, whether an arrest was made and the basic demographic information about each victim.


Read in the data.

```{r}
homocide_df = 
  read_csv("homicide_data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```


Let's look at this a bit

```{r}
aggregate_df = 
  homocide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Can I do a prop test for a single city?

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Try to iterate .......

```{r}
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

Create a plot that shows the estimates of the proportion of unsolved homicides and CIs for each city.

```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  labs(title = "Estimates of the proportion of unsolved homicides and CIs for city") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```



## Problem 2

Iterate over the file names, read in data for each subject, and save the result as a new variable.

```{r}
path_df = 
  tibble(
    subject = list.files("lda_data"),
  ) %>% 
  mutate(
    path = str_c("lda_data/", subject),
    data = map(.x = path, ~read_csv(.x))
  ) 
```

Tidy the result: manipulate file names to include control arm and subject ID, and pivot the data from wide to long.

```{r}
study_df = 
  path_df %>% 
  select(-path) %>% 
  unnest(data) %>% 
  mutate(subject = str_replace_all(subject, ".csv", "")) %>% 
  separate(subject, into = c("arm", "subject_id"), remove = FALSE) %>% 
  mutate(arm = recode(arm, "con" = "control","exp" = "experimental")) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "obs"
  ) 
```

Make a spaghetti plot showing observations on each subject over time.

```{r}
study_df %>% 
  ggplot(aes(x = week, y = obs, group = subject, color = arm)) +
  geom_line() +
  labs(title = "Observations on each subject over time")
```

Overtime, for the experimental arm, observations tend to increase while for the control arm, observations almost stay the same.



## Problem 3

Generate 5000 datasets from the normal distribution, save estimated means from simulation and and p-values from t test.

```{r}
sim_mean_p = function(samp_size = 30, mu, sigma = 5) {
  
  sim_data = 
    tibble(
      x = rnorm(n = samp_size, mean = mu, sd = sigma)
    )
  
  sim_data %>% 
    t.test() %>% 
    broom::tidy() %>% 
    select(estimate, p.value)
  
}

sim_results = 
  rerun(5000, sim_mean_p(mu = 0)) %>% 
  bind_rows()
```

Repeat the above for µ = {1,2,3,4,5,6}.

```{r}
sim_results =
  tibble(
    mu_value = c(1:6)
  ) %>% 
    mutate(
      output_lists = map(.x = mu_value, ~rerun(5000, sim_mean_p(mu = .x))),
      estimate_df = map(output_lists, bind_rows)
    ) %>% 
    select(-output_lists) %>% 
    unnest(estimate_df)
```

Make a plot showing the proportion of times the null was rejected (power) vs. the true value of µ.

```{r}
rejected_df = 
  sim_results %>% 
  mutate(rejected = ifelse(p.value < 0.05, "reject", "not reject"))

rejected_df %>%
  group_by(mu_value) %>% 
  summarize(prop_rejected = sum(rejected == "reject")/n()) %>% 
  ggplot(aes(x = mu_value, y = prop_rejected)) +
  geom_bar(stat = "identity") +
  labs(x = "true value of µ", y = "power",
       title = "Power vs. True value of µ")
```

Since we assume µ = 0 and effect size is calculated by the true value of µ - 0 = true value of µ, we can treat x axis as a representation of effect size.
As effect size increases, power also increases - from fast to slow, until power reaches 1.



Make a plot showing the average estimate of µ-hat vs. the true value of µ, overlay with a plot showing the average estimate of µ-hat only in samples for which the null was rejected vs. the true value of µ.

```{r}
all_plot_df = 
  rejected_df %>%
  group_by(mu_value) %>% 
  summarize(mean_mu = mean(estimate)) %>% 
  mutate(samples = "all") 

rejected_plot_df = 
  rejected_df %>%
  filter(rejected == "reject") %>% 
  group_by(mu_value) %>% 
  summarize(mean_mu = mean(estimate)) %>% 
  mutate(samples = "reject")


ggplot(data = all_plot_df, aes(x = mu_value, y = mean_mu, color = samples)) + 
  geom_point() + 
  geom_point(data = rejected_plot_df) +
  labs(x = "true value of µ", y = "average estimate of µ-hat",
       title = "Average estimate of µ-hat vs. True value of µ")
```

When µ is smaller than 3, the sample average of µ-hat across tests for which the null is rejected approximately equal to the true value of µ. But µ gets larger, the sample average of µ-hat across tests where the null is rejected approaches (even coincides with) the true value of µ.

* The reasoning:
In the previous bar graph, we can see the power is relatively low when µ is smaller than 3, which means the proportion of times the null was rejected is low. Therefore, for µ smaller than 3, the number of samples with rejected null is relatively small. These sample means indeed have more variation and their average is more likely to deviate from the true mean. However, as µ gets bigger, there are more samples with rejected null, so the sample average of µ-hat becomes more stable and yields a more unbiased estimation of the true mean.

 